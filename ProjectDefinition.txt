-------------------------------------

Project Definition

-------------------------------------


Goals:
	1. Gain experience with research.
	2. Prototype a new signal processing system with the ~ 5.2 Terabyte raw data set to hopefully flag RFI from the raw data. This flagged data will be removed before the data compression. 
	3. Assuming goal #1 has been satisfied, take a sample of the program and compare different methods to speed up the data processing through parallelization. 
	4. Process data in real time in parallel with existing data acquisition system to compare FRSC system to existing.



Timeline of my project over 12 weeks:
	Step 1. Define project expectations and lay down infrastructure to do good work in the following weeks. (week 1)
	Step 2.	Familiarize with data file data format and the programs that Steve and Richard already made. These current programs already produce spectrograms and they flag files as well. (Week 2) 
	Step 3. Do a trade study on three different options. All use python and/or C++. (Week 3)
		a. Investigate a Full GNU Radio implementation to do all of the DSP using Theano or other modules that can utilize the GPU parallization functionality.
		b. Investigate cuda (Nvidia) with native python and C++ to implement DSP utilizing the GPU.
		c. Investigate Thrust or other GPU packages with python and / or C++ to utilize the GPU for DSP.
	Step 4. Benchmark Implementation (simple but representative). Implement a part of the code in all three options of step 3 to profile the best option, given step three had no clear winner. After Benchmark implementation, if there is still no clear winner, GNU Radio should be implemented. (Week 5 - deadline of July 18th, 2016)
	Step 5. Implement which ever option won out from the Trade Study. (Weeks 6-10)
	Step 6. Clean up the project. Create a presentation. Tie together documentation. (weeks 10-12)
	Step *. Documentation. Clear description of outputs of flagging program in both a logical manner and in a technical manner.

*Documentation should be done in every step in every week. Documentation should be assembled as the project grows. Documentation should not be written after the project is finished.


Revisions:
---------------------------------------
06/27/2016-
	Step 3. Check out Joe?s implementation of Steve?s code from Github, and get that working. This will utilize the GPU card.
		  - Locate a machine that can access GPU
		  - Make sure you have all necessary libraries to do so. 
	Step 4. . . . .   F I N I S H   L A T E R   . . . . .


What I have done so far step by step.
1. Researched on DSP principles, gaussian white noise, statistics, complex numbers and signals, astronomy terms and practices in general.
2. Read Steve Ellington's code and decifered what I could.
3. attended multiple astronomy/ astrophysics lectures (wk 1).
4. Learned to a deeper extent the language of C/C++.
5. Learned the physical GBT system that delt with the analog and digital signal from the sky.
6. Read Steve Ellingon's code more and understood most all of it. 
7. Devised project scope, parameters, and goals.
8. Fixed, recompiled and ran Steve's rg.c code that was his first code to use the data in the GUPPI Raw data format. 
9. Derived how mixing to an intermediate frequency can be achieved with analog systems. 
10. learned more about python and how to manipulate arrays. 
11. Learned what stokes parameters really were.
11. Was introduced to Joe Brandt. Read Joe's code that ran frsc with all 32 channels in parallel. 
12. Reproduced the output of Joe Brandt's gpu frsc code to verify the correctness of his code (was believed to be incomplete).
13. Rewrote tutorial CUDA code from a book to learn both CUDA and the structure of the GPU.
14. Finally documented and drew a graph of the GUPPI raw data format. No more ambiguity!
15. Gave a 5 minute presentation about my project to the Charlottesville summer students.
16. Developed my own code that would take GUPPI raw data and produce a spectrogram utilizing the GPU.
17. Learned plotting in python better and plotted said spectrogram.
18. Produced many spectrogram plots (not all channels, just the interesting ones).
19. Learned about fft shifting. Fixed plots. Produced both spectrograms and time series and frequency series. I am not sure about time and frequency series with corrected or incorrect fft shifting. 
20. Diagrammed out the data.
21. Diagrammed out the gpu system (prone to change).
22. Made the fft code much more flexable. It now can be modified for different FFT_SIZEs and different amounts of data. The average I think can be changed, but I will have to double check on that.
23. I started messing around with statistics. 
24. Successfully got my moment calculations accurate with help from python and python's histogram that was copy pasted into my code.
25. Got my char histogram to work. I used the one from the cuda book.
26. Switched variables and memory from doing xr xi yr yi to doing xx and yy. 
27. Produced 1 file with all good statistics for mean max rms skew kurtosis. 





----------------------------------------------------------------

more revisions:

So I was planning on putting my gpu code onto one of the GPUs that are in Guppi, but then that changed to Vegas because guppi is going to be out of data soon. So we had a meeting, joe, ray, richard, and myself to discuss what the vegas packet format is and how I could easily implement my code into the existing vegas infrastructure. The answer is that it is not something that is very trivial. It would take some work for me to actually implement my code on it. Understanding the vegas packet format is easy and I could probably explain that to you right now. However, there are a whole bunch of other management that has to be aware of what i am doing. For instance. My code will be compounding the data and processing it which slows it down. At somepoint, my flagging will be encorporated back into the regular data stream, so the current data stream needs to be buffered or something. This is a timing concern. More processesing would have to happen to actually replace that data with 'nan' or something. That is not what my program would directly do. If my program does not run at the current processing speed that the data is sent, then either, I need to only run it on some channels and not all, or I need to process one chunk of data, drop one chunk of data, process one chunk of data, drop one chunk of data, etc... This would create problems with hooking up to the current system. Even if my program what running at or faster than the speed the data was entering, the inclusion of my program and the copying/ diverting data to my program and back from my program would be the real hard part. This all is doable, but I do not have the time to familiarize myself with all of the code and tricks and new terminology much less create a pipe line that is ingenious. 
	So the second idea was to just write a chunk of vegas data to disk and simulate my program with stored vegas data instead of stored guppi data. The current infrastructure does not have a known reliable program that will dump vegas data to a disk. There is a diagnostic program that was used for guppi that was modified for vegas that I am not sure if was even implemented with vegas yet. It is conceivable that this program could be the magic bullet that can write the vegas data to disk, or it could crash because it is not tested yet. This program is supposed to grab real time data and write it to lustre probably. 
	An alternative idea was to take this diagnostic program and manipulate it to instead of dumping the realtime data when it grabs it, to send that data to my program. This would mean that my program would have to accept vegas packets already and this would be a hack that could be the pipe line. In a more professional application, this would not be the perfered pipeline of choice.  
	After much discussion, a course of action was descided upon. I am to work on increasing the speed of my program until the program can run at or faster than real time data stream. I am to improve the methods of statistical calculations. I am to make my program compatible for multiple types of calculations like an assortment of statistic calculations to choose from, the time resolution of the spectrogram and calculations, the option of spectrogram, timeseires, or bandwidth, the option of using data stored from a file in guppi format, a file stored in vegas format, or a stream in real time in vegas packet format. There should be a good menu that describes all the options and makes it user friendly. The code should be well documented, commented, and easy to read, and it should be organized logically. first priority is speed, second is legibility, third is versitility. Part of this program documentation should be the benchmarking of different implementations of code, different statistic calculations, different modes after finilization. Benchmarking is key.
	At the end of this summer experience, I will have a program that is thoroughly tested, benchmarked, and documented so it can be easily used in the vegas processesing. This should be able to be implemented by someone who has not worked with my code before very easily, and all parameters must be variables not hard coded numbers to allow flexablility. All variable calculations should be logical and easy to understand.
	The different statistic calculations to be tested and benchmarked and compared to both frsc and frsc_gpu are Histogram method, histogram with concatenation method, and lastly recurrence relation method that can concatenate but doesn't need to. Documentation and or presentation needs to have the theory behind all calculations, the theory behind all background, and the theory behind what my project can bring other people. What are the potential positive benefits of having this program and also how can it be improved. Can this program be easily modified to work for a varitey of applications. is this a good test for inline statisitics or not? 

Strat for week 8 . . .

Not part of the project definition, but I do need to write down my thoughts on my statistics programming. I already have a statistics program that calculates mean varience skew and kurtosis, but I am not sure about their correctness or accuracy. To test this I will be using a collection of distributions with well known values for the four statistics above. I will make the distribution array in python because of all of the premade libraries. I will then find the statistics from those distributions on both my program and python programs. With the same random data, both programs should yield the exact same answer. 
	
Next I will find out what good threshold I should set for the RFI flagging. It may be 5 sigma. I will look at the histogram and decide about rms of the histogram and other calculations like that.

To research random noise, I will read up on that link that Richard sent me so I can understand what type of distribution to pull my random variables from when. 

To research good GPU programming techniques, I will use google scholar to get tips on good GPU coding practices.

Then work on making the gpu code faster
	-shared memory
	-more data at once
	-atomic options
	-shared memory
	-sub-histograms

Then work on making the gpu code more modular and editable.

Editable means portable too!

You are done.



For your gpu calculations make sure to account for computer programming error. This can be seen from the math functions of http://docs.nvidia.com/cuda/cuda-math-api/group__CUDA__MATH__SINGLE.html#group__CUDA__MATH__SINGLE appendix D.1 Table 6




















